{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression Health Costs Calculator**"
      ],
      "metadata": {
        "id": "RXeeVl6SZyfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project was undertaken as part of FreeCodeCamp's Machine Learning certification. **The goal was to predict medical expenses based on various demographic and lifestyle factors using a neural network model.**"
      ],
      "metadata": {
        "id": "-Hw3Mw88aDHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Dive Right In"
      ],
      "metadata": {
        "id": "rqBvTni9aHgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "HVSwHE54SJ-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "QfhdXrWsSNW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have explored and visualised our data Next we:                                               \n",
        "**Prepare Data:** The categorical columns are converted to numerical values to prepare the dataset for training machine learning models, which typically require numerical inputs.                                                   \n",
        "**Shuffle Data:** Shuffling the dataset ensures that the order of data does not bias the learning process.                       \n",
        "**Split data:** Splitting the dataset into training and testing sets allows for model training on one portion of the data and evaluation on unseen data to assess model performance."
      ],
      "metadata": {
        "id": "ceKCe-_WRcaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcopvQh3X-kX"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numbers\n",
        "dataset[\"sex\"].replace(\n",
        "    [\"female\", \"male\"],\n",
        "    [0, 1],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "dataset[\"smoker\"].replace(\n",
        "    [\"no\", \"yes\"],\n",
        "    [0, 1],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "dataset[\"region\"].replace(\n",
        "    ['southwest', 'southeast', 'northwest', 'northeast'],\n",
        "    [0, 1, 2, 3],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Assuming 'dataset' is already defined and contains the data\n",
        "\n",
        "dataset = shuffle(dataset).reset_index(drop=True)\n",
        "\n",
        "# Separating the train and test datasets\n",
        "train_dataset  = dataset[0:int(0.8*dataset.shape[0])]\n",
        "test_dataset = dataset[int(0.8*dataset.shape[0]):dataset.shape[0] - 1]\n",
        "\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now processed our data, **We are ready to CREATE and Build OUR MODEL.**                                   \n",
        "Next we  set up a **neural network** model for regression using TensorFlow/Keras. It begins by normalizing the input data using a normalization layer adapted to the training dataset. The sequential model architecture includes dense layers with ReLU activation, culminating in an output layer for regression predictions."
      ],
      "metadata": {
        "id": "Ib2RVdW2SxPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a normalization layer and adapting it to the training dataset\n",
        "normalizer = layers.experimental.preprocessing.Normalization()\n",
        "normalizer.adapt(np.array(train_dataset))\n",
        "\n",
        "# Defining a sequential model with normalization, dense layers, and an output layer\n",
        "model = keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model with Adam optimizer, MAE loss function, and metrics for evaluation\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mae',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "\n",
        "# Building the model to infer input shape and displaying a summary of its architecture\n",
        "model.build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Kke52LTOSkX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Model is now set up, which means we ready to Train it using the dataset and this is After compiling the model with an Adam optimizer and MAE loss, we train the model on the training dataset for **100 epochs to optimize performance metrics such as MAE and MSE**."
      ],
      "metadata": {
        "id": "4F29heN2T-aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on the training dataset for 100 epochs\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "id": "dLY6GpzMUW60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we TEST, TEST , TEST and test. Our aim is to have this model return a **Mean Absolute Error of under 3500**. This means it predicts health care costs correctly within $3500."
      ],
      "metadata": {
        "id": "wnEteZtzUnkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YEEEEEY!!! WE PASSED the challenge! Our model achieved a **mean absolute error** **(MAE) of 2078.07 on the testing set**, which is below the threshold of 3500. This indicates that your model performs well in predicting expenses based on the evaluation metrics provided."
      ],
      "metadata": {
        "id": "8GKu9P0ZWOCm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}